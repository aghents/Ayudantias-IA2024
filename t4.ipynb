{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo preparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages (from gymnasium) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages (from gymnasium) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"gymnasium\" pygame --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['arbol_1', -71.04884881461739, -32.84038990910421],\n",
       "       ['arbol_2', -71.04958858366999, -32.8404821794963],\n",
       "       ['arbol_3', -71.04980926215778, -32.8404058633257],\n",
       "       ['arbol_4', -71.0504699980531, -32.8405182859727],\n",
       "       ['arbol_5', -71.04922664888424, -32.841015251972266],\n",
       "       ['arbol_6', -71.04926942588176, -32.84039520943775],\n",
       "       ['arbol_7', -71.05106578768262, -32.84165715069143],\n",
       "       ['arbol_8', -71.05020361505561, -32.84156011856145],\n",
       "       ['arbol_9', -71.05126745558296, -32.84087006184975],\n",
       "       ['arbol_10', -71.04878320531743, -32.84040113716143],\n",
       "       ['arbol_11', -71.04989114149105, -32.84091401967176],\n",
       "       ['arbol_12', -71.04982643476353, -32.84062894259972],\n",
       "       ['arbol_13', -71.0498936842084, -32.84108028071009],\n",
       "       ['arbol_14', -71.04892222652431, -32.84102148268019],\n",
       "       ['arbol_15', -71.05078948279294, -32.84109184771386],\n",
       "       ['arbol_16', -71.04984082279348, -32.84135804156654],\n",
       "       ['arbol_17', -71.0509749755355, -32.840996174799784],\n",
       "       ['arbol_18', -71.05061250248175, -32.84127395801135],\n",
       "       ['arbol_19', -71.04985199310713, -32.84033754789535],\n",
       "       ['arbol_20', -71.05048455311143, -32.84062681717981],\n",
       "       ['arbol_21', -71.0510759669852, -32.84043995071005],\n",
       "       ['arbol_22', -71.04980868021866, -32.841318740768784],\n",
       "       ['arbol_23', -71.0499594694395, -32.84048198844626],\n",
       "       ['arbol_24', -71.04903564440758, -32.84086452301077],\n",
       "       ['arbol_25', -71.04885395281717, -32.84118897257884],\n",
       "       ['arbol_26', -71.05012870014684, -32.840717761576705],\n",
       "       ['arbol_27', -71.05049835709781, -32.84039118351497],\n",
       "       ['arbol_28', -71.05065595988785, -32.84066837455132],\n",
       "       ['arbol_29', -71.05043893649238, -32.841200878994314],\n",
       "       ['arbol_30', -71.04875112669016, -32.841152584382066],\n",
       "       ['arbol_31', -71.04881651772966, -32.84070851953516],\n",
       "       ['arbol_32', -71.05098348112861, -32.84138020240415],\n",
       "       ['arbol_33', -71.05113481102975, -32.84119136211165],\n",
       "       ['arbol_34', -71.05026646878107, -32.84069191912676],\n",
       "       ['arbol_35', -71.04895950751573, -32.840514629482264],\n",
       "       ['arbol_36', -71.05046270432774, -32.84102966528912],\n",
       "       ['arbol_37', -71.05031776421953, -32.84084956555882],\n",
       "       ['arbol_38', -71.05082056329235, -32.84040226870655],\n",
       "       ['arbol_39', -71.05113965167094, -32.84130660368185],\n",
       "       ['arbol_40', -71.0500141179412, -32.84048403625278],\n",
       "       ['arbol_41', -71.05120075143927, -32.84127550087025],\n",
       "       ['arbol_42', -71.0501425761934, -32.84133370429631],\n",
       "       ['arbol_43', -71.04966489350393, -32.84072077283356],\n",
       "       ['arbol_44', -71.05036882498041, -32.84138541504808],\n",
       "       ['arbol_45', -71.0502547248888, -32.84094458062327],\n",
       "       ['arbol_46', -71.05009458902333, -32.84029601330805],\n",
       "       ['arbol_47', -71.05004260280815, -32.8405035143179],\n",
       "       ['arbol_48', -71.05069303233194, -32.84117945727619],\n",
       "       ['arbol_49', -71.05033240740188, -32.84076135787305],\n",
       "       ['arbol_50', -71.0513128848975, -32.84065273857881],\n",
       "       ['arbol_51', -71.05072341119893, -32.84135935899337],\n",
       "       ['arbol_52', -71.05030842687727, -32.840358885171774],\n",
       "       ['arbol_53', -71.05112104149092, -32.84065831938045],\n",
       "       ['arbol_54', -71.05070669357676, -32.840832061924736],\n",
       "       ['arbol_55', -71.04999400490523, -32.840931685358825],\n",
       "       ['arbol_56', -71.04927072494543, -32.840247722616624],\n",
       "       ['arbol_57', -71.05005004556978, -32.840692793843964],\n",
       "       ['arbol_58', -71.04918316206461, -32.840355464570926],\n",
       "       ['arbol_59', -71.05112860352904, -32.84057280202327],\n",
       "       ['arbol_60', -71.05091692575762, -32.8403329068033],\n",
       "       ['arbol_61', -71.0488406690748, -32.84113153294749],\n",
       "       ['arbol_62', -71.04911399378302, -32.84034233075505],\n",
       "       ['arbol_63', -71.05038931536473, -32.84146505812756],\n",
       "       ['arbol_64', -71.05106595767057, -32.84098019185551],\n",
       "       ['arbol_65', -71.04976163323097, -32.84136054042839],\n",
       "       ['arbol_66', -71.05074697127934, -32.84110993206395],\n",
       "       ['arbol_67', -71.04852938930965, -32.84119245155548],\n",
       "       ['arbol_68', -71.04957953411527, -32.840517360952205],\n",
       "       ['arbol_69', -71.05060199765158, -32.840478317741905],\n",
       "       ['arbol_70', -71.05022630667872, -32.840339123336676],\n",
       "       ['arbol_71', -71.04964653544846, -32.84108296393436],\n",
       "       ['arbol_72', -71.04918907953325, -32.84137156987902],\n",
       "       ['arbol_73', -71.04965947309846, -32.84087443322667],\n",
       "       ['arbol_74', -71.04899572751889, -32.840509832173545],\n",
       "       ['arbol_75', -71.05031264793419, -32.841089614215214],\n",
       "       ['arbol_76', -71.04892439803471, -32.84131675194178],\n",
       "       ['arbol_77', -71.04959557663584, -32.840648036075606],\n",
       "       ['arbol_78', -71.04903353547594, -32.84072018908305],\n",
       "       ['arbol_79', -71.05027128324627, -32.84043916916365],\n",
       "       ['arbol_80', -71.05073049922427, -32.84149546009366],\n",
       "       ['arbol_81', -71.05110242833219, -32.84110771105979],\n",
       "       ['arbol_82', -71.0493102998651, -32.84066239168067],\n",
       "       ['arbol_83', -71.05047628259851, -32.84128817016044],\n",
       "       ['arbol_84', -71.05021388561838, -32.841504407412515],\n",
       "       ['arbol_85', -71.05108647173056, -32.84038956996106],\n",
       "       ['arbol_86', -71.04920802907753, -32.84093485247053],\n",
       "       ['arbol_87', -71.05021411852493, -32.84055205145941],\n",
       "       ['arbol_88', -71.05080054142009, -32.840690521284465],\n",
       "       ['arbol_89', -71.0498120743422, -32.840494509905],\n",
       "       ['arbol_90', -71.05104580248336, -32.84086012963571],\n",
       "       ['arbol_91', -71.04963372091649, -32.84141432937953],\n",
       "       ['arbol_92', -71.05121493104583, -32.84079973345295],\n",
       "       ['arbol_93', -71.04982648460124, -32.840443535227635],\n",
       "       ['arbol_94', -71.05126798143885, -32.84100975555335],\n",
       "       ['arbol_95', -71.05046217607249, -32.84032772344226],\n",
       "       ['arbol_96', -71.04868387275978, -32.84071933438925],\n",
       "       ['arbol_97', -71.05044931126673, -32.841621307181114],\n",
       "       ['arbol_98', -71.0500146842755, -32.841086781687835],\n",
       "       ['arbol_99', -71.05013607256952, -32.84057434609113],\n",
       "       ['arbol_100', -71.05032708530439, -32.840317762845075],\n",
       "       ['arbol_101', -71.05008314623846, -32.841112978497236],\n",
       "       ['arbol_102', -71.04999940371013, -32.84055791821304],\n",
       "       ['arbol_103', -71.04919693682265, -32.84090862079151],\n",
       "       ['arbol_104', -71.05058323513478, -32.84066542952486],\n",
       "       ['arbol_105', -71.05017891230813, -32.840412852039115],\n",
       "       ['arbol_106', -71.0491430092358, -32.84092797234648],\n",
       "       ['arbol_107', -71.04899579866124, -32.841033605701874],\n",
       "       ['arbol_108', -71.04991683175042, -32.84051657461151],\n",
       "       ['arbol_109', -71.05107083549451, -32.84114793848422],\n",
       "       ['arbol_110', -71.0490852546023, -32.840731564793586],\n",
       "       ['arbol_111', -71.05108436377122, -32.84151631306822],\n",
       "       ['arbol_112', -71.0508079978396, -32.8408698442806],\n",
       "       ['arbol_113', -71.0491716229467, -32.84123364382249],\n",
       "       ['arbol_114', -71.0510157336784, -32.84084560595953],\n",
       "       ['arbol_115', -71.04873508562217, -32.84061870509962],\n",
       "       ['arbol_116', -71.05111420676296, -32.841528676680376],\n",
       "       ['arbol_117', -71.05013305578683, -32.84122223662006],\n",
       "       ['arbol_118', -71.05105423530935, -32.84170935008915],\n",
       "       ['arbol_119', -71.05043227114813, -32.84095425861342],\n",
       "       ['arbol_120', -71.04931920988626, -32.84077091400309],\n",
       "       ['arbol_121', -71.05109025088593, -32.841216195749936],\n",
       "       ['arbol_122', -71.04886031729275, -32.84080470287064],\n",
       "       ['arbol_123', -71.05094705349872, -32.84035961651284],\n",
       "       ['arbol_124', -71.05025984522163, -32.840654476458354],\n",
       "       ['arbol_125', -71.04961621291027, -32.84045375021859],\n",
       "       ['arbol_126', -71.04859757802646, -32.84086325556125],\n",
       "       ['arbol_127', -71.05047265424804, -32.84028984950454],\n",
       "       ['arbol_128', -71.05123054694495, -32.84109925314074],\n",
       "       ['arbol_129', -71.0497524572403, -32.84049080550871],\n",
       "       ['arbol_130', -71.05082295672015, -32.84111092309041],\n",
       "       ['arbol_131', -71.04986842421977, -32.84064608893798],\n",
       "       ['arbol_132', -71.0511727016702, -32.8411816274926],\n",
       "       ['arbol_133', -71.05010452759764, -32.84046725695026],\n",
       "       ['arbol_134', -71.05091369976589, -32.84094515034208],\n",
       "       ['arbol_135', -71.04865742663026, -32.84109260323776],\n",
       "       ['arbol_136', -71.04953239757076, -32.84061970244106],\n",
       "       ['arbol_137', -71.0505262619817, -32.841444117582],\n",
       "       ['arbol_138', -71.0491360859219, -32.84054287113617],\n",
       "       ['arbol_139', -71.04993814822296, -32.84131007290993],\n",
       "       ['arbol_140', -71.049105953629, -32.84092263223956],\n",
       "       ['arbol_141', -71.04960713929279, -32.84021460798801],\n",
       "       ['arbol_142', -71.04890581951109, -32.84043383478482],\n",
       "       ['arbol_143', -71.04914641589063, -32.8404197302244],\n",
       "       ['arbol_144', -71.04899231463006, -32.84104882012433],\n",
       "       ['arbol_145', -71.05111151194758, -32.841194333094215],\n",
       "       ['arbol_146', -71.0501094124919, -32.84057585950839],\n",
       "       ['arbol_147', -71.04868920166153, -32.84125257041686],\n",
       "       ['arbol_148', -71.04968211752143, -32.8406185483422],\n",
       "       ['arbol_149', -71.04896363939096, -32.84086349331505],\n",
       "       ['arbol_150', -71.05020887875139, -32.84116585878307],\n",
       "       ['arbol_151', -71.04911305227928, -32.840748233517246],\n",
       "       ['arbol_152', -71.049475189306, -32.84063148300883],\n",
       "       ['arbol_153', -71.04990679738074, -32.84035514983017],\n",
       "       ['arbol_154', -71.04922151943315, -32.84029165770834],\n",
       "       ['arbol_155', -71.05114070692434, -32.84060896615584],\n",
       "       ['arbol_156', -71.04924839277243, -32.84051429963181],\n",
       "       ['arbol_157', -71.05031593367595, -32.84090309585148],\n",
       "       ['arbol_158', -71.04875443643553, -32.84057051756525],\n",
       "       ['arbol_159', -71.05096389337872, -32.84086715485454],\n",
       "       ['arbol_160', -71.04998450518657, -32.84070374808989],\n",
       "       ['arbol_161', -71.0502052209611, -32.84033031105205],\n",
       "       ['arbol_162', -71.04922762462748, -32.840774464171574],\n",
       "       ['arbol_163', -71.05128103536933, -32.84101836107675],\n",
       "       ['arbol_164', -71.04943812999969, -32.84101696197436],\n",
       "       ['arbol_165', -71.04937704772459, -32.84075343954824],\n",
       "       ['arbol_166', -71.05030729332769, -32.84083083610376],\n",
       "       ['arbol_167', -71.0509060233581, -32.84122235347505],\n",
       "       ['arbol_168', -71.04994138163482, -32.840289281189364],\n",
       "       ['arbol_169', -71.05038680620126, -32.84033643027596],\n",
       "       ['arbol_170', -71.05157642310895, -32.84058758663222],\n",
       "       ['arbol_171', -71.04911421408869, -32.84134653703021],\n",
       "       ['arbol_172', -71.05025338548512, -32.840531082730244],\n",
       "       ['arbol_173', -71.05042558080775, -32.8409812786264],\n",
       "       ['arbol_174', -71.05133776783185, -32.84057486746652],\n",
       "       ['arbol_175', -71.04863908259163, -32.84082213181876],\n",
       "       ['arbol_176', -71.0509076673854, -32.84110724294372],\n",
       "       ['arbol_177', -71.04925669816687, -32.84119123660367],\n",
       "       ['arbol_178', -71.05003673379848, -32.84081291107093],\n",
       "       ['arbol_179', -71.05002851898693, -32.84077677292313],\n",
       "       ['arbol_180', -71.04873600438351, -32.8410688239219],\n",
       "       ['arbol_181', -71.05017493368163, -32.84131557077309],\n",
       "       ['arbol_182', -71.05101701710302, -32.84076175598094],\n",
       "       ['arbol_183', -71.04940585776522, -32.8408950822104],\n",
       "       ['arbol_184', -71.04883332300932, -32.84101119810271],\n",
       "       ['arbol_185', -71.04995396685264, -32.84138238163256],\n",
       "       ['arbol_186', -71.0489743810239, -32.840225457696384],\n",
       "       ['arbol_187', -71.048914513183, -32.840450820532936],\n",
       "       ['arbol_188', -71.05086804474637, -32.84064695144783],\n",
       "       ['arbol_189', -71.04938129056181, -32.840987954963886],\n",
       "       ['arbol_190', -71.05130304230188, -32.841165024986005],\n",
       "       ['arbol_191', -71.04934069791696, -32.84031564872814],\n",
       "       ['arbol_192', -71.05145243673317, -32.84058975438566],\n",
       "       ['arbol_193', -71.0508769124792, -32.840605759321654],\n",
       "       ['arbol_194', -71.04912120967806, -32.840561742856885],\n",
       "       ['arbol_195', -71.05023329807811, -32.84138181812405],\n",
       "       ['arbol_196', -71.04933468203832, -32.84089830862198],\n",
       "       ['arbol_197', -71.04878654158414, -32.84106692436144],\n",
       "       ['arbol_198', -71.04963384761463, -32.841098576565734],\n",
       "       ['arbol_199', -71.04864354690761, -32.84112273459789],\n",
       "       ['arbol_200', -71.04958574198693, -32.841381316811336],\n",
       "       ['arbol_201', -71.05028901884685, -32.84145362826348],\n",
       "       ['arbol_202', -71.04852999569172, -32.84113898953683],\n",
       "       ['arbol_203', -71.04858309403521, -32.84109225211864],\n",
       "       ['arbol_204', -71.04941962766159, -32.841152810505726],\n",
       "       ['arbol_205', -71.04995844216316, -32.84089233533492],\n",
       "       ['arbol_206', -71.05110689911474, -32.84072892792074],\n",
       "       ['arbol_207', -71.05115410458554, -32.840821950283015],\n",
       "       ['arbol_208', -71.04937761665931, -32.840959347381286],\n",
       "       ['arbol_209', -71.04890008905831, -32.840492325665124],\n",
       "       ['arbol_210', -71.05085306399569, -32.84080768851778],\n",
       "       ['arbol_211', -71.05063726801826, -32.84129153462845],\n",
       "       ['arbol_212', -71.05043656915421, -32.84062046899988],\n",
       "       ['arbol_213', -71.04887828995844, -32.84046414306868],\n",
       "       ['arbol_214', -71.0505280130593, -32.840362040376135],\n",
       "       ['arbol_215', -71.04867961166083, -32.84101451003054],\n",
       "       ['arbol_216', -71.05061555074383, -32.84162781779459],\n",
       "       ['arbol_217', -71.05054655108974, -32.84049490227489],\n",
       "       ['arbol_218', -71.0514240020227, -32.840614801021886],\n",
       "       ['arbol_219', -71.0500172877953, -32.840573901641335],\n",
       "       ['arbol_220', -71.04900028299892, -32.84079418383142],\n",
       "       ['arbol_221', -71.05046001598332, -32.84085680435265],\n",
       "       ['arbol_222', -71.050616756124, -32.841377740740015],\n",
       "       ['arbol_223', -71.05106169848104, -32.841656111114645],\n",
       "       ['arbol_224', -71.0495495798956, -32.841321281274006],\n",
       "       ['arbol_225', -71.04960420550736, -32.84069046993898],\n",
       "       ['arbol_226', -71.05052021773959, -32.84137626573121],\n",
       "       ['arbol_227', -71.05150421230735, -32.84044900907001],\n",
       "       ['arbol_228', -71.0497755093686, -32.841297731905605],\n",
       "       ['arbol_229', -71.0493507690697, -32.84057891309102],\n",
       "       ['arbol_230', -71.0508388663359, -32.84144134374193]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load npy file\n",
    "tree_data = np.load('paltos(3).npy', allow_pickle=True)\n",
    "tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsp_game\n",
    "\n",
    "# Register the TravelingSalesman environment\n",
    "tsp_game.register_environment()\n",
    "\n",
    "# Create the TravelingSalesman environment\n",
    "env = gym.make('TravelingSalesman-v0', tree_data=tree_data, blocked_percentage=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be int32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be int32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/agustin/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[38;5;28;01melif\u001b[39;00m truncated:\n\u001b[1;32m     45\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum steps reached! Press \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to reset or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     50\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/wrappers/common.py:409\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/wrappers/common.py:303\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tareasia/tsp_game.py:217\u001b[0m, in \u001b[0;36mTravelingSalesmanEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m tree_here \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree_id, tree_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_positions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_pos\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    218\u001b[0m         tree_here \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tree_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_trees:\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;66;03m# Draw X for visited tree\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/numpy/_core/numeric.py:2557\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[0;32m-> 2557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builtins\u001b[38;5;241m.\u001b[39mbool(\u001b[43m(\u001b[49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a1 \u001b[38;5;129;01mis\u001b[39;00m a2:\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;66;03m# nan will compare equal so an array will compare equal to itself.\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/numpy/_core/_methods.py:74\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tsp_game\n",
    "\n",
    "# Register the TravelingSalesman environment\n",
    "tsp_game.register_environment()\n",
    "\n",
    "# Create the TravelingSalesman environment\n",
    "env = gym.make('TravelingSalesman-v0', tree_data=tree_data, blocked_percentage=0.2)\n",
    "\n",
    "# Add a running attribute to the environment\n",
    "env.running = True\n",
    "    \n",
    "# Reset the environment\n",
    "observation, info = env.reset()\n",
    "    \n",
    "while env.running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            env.running = False\n",
    "            break\n",
    "        \n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            action = None\n",
    "            if event.key == pygame.K_UP:\n",
    "                action = 0\n",
    "            elif event.key == pygame.K_DOWN:\n",
    "                action = 1\n",
    "            elif event.key == pygame.K_LEFT:\n",
    "                action = 2\n",
    "            elif event.key == pygame.K_RIGHT:\n",
    "                action = 3\n",
    "            elif event.key == pygame.K_r:  # Reset game\n",
    "                observation, info = env.reset()\n",
    "                continue\n",
    "            elif event.key == pygame.K_q:  # Quit game\n",
    "                env.running = False\n",
    "                break\n",
    "            \n",
    "            if action is not None:\n",
    "                observation, reward, done, truncated, info = env.step(action)\n",
    "                env.render()\n",
    "                \n",
    "                if done:\n",
    "                    print(\"Goal reached! Press 'R' to reset or 'Q' to quit\")\n",
    "                elif truncated:\n",
    "                    print(\"Maximum steps reached! Press 'R' to reset or 'Q' to quit\")\n",
    "    \n",
    "    env.render()\n",
    "    pygame.time.wait(50)\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     83\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Q[\u001b[38;5;28mtuple\u001b[39m(state)])\n\u001b[0;32m---> 84\u001b[0m     next_state, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     best_route\u001b[38;5;241m.\u001b[39mappend(next_state)\n\u001b[1;32m     86\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tareasia/tsp_game.py:154\u001b[0m, in \u001b[0;36mTravelingSalesmanEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Check if we're on a tree\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree_id, pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_positions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tree_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_trees:\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_trees\u001b[38;5;241m.\u001b[39madd(tree_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/qlearning/lib/python3.13/site-packages/numpy/_core/numeric.py:2489\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dtype_cannot_hold_nan\u001b[39m(dtype):\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dtype) \u001b[38;5;129;01min\u001b[39;00m _no_nan_types\n\u001b[0;32m-> 2489\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_array_equal_dispatcher)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_equal\u001b[39m(a1, a2, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;124;03m    True if two arrays have the same shape and elements, False otherwise.\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Initialize Q-table\n",
    "Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "# Define parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_decay = 0.995\n",
    "min_epsilon = 0.01\n",
    "num_episodes = 1\n",
    "\n",
    "# Function to choose action based on epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # Exploit\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = choose_action(tuple(state))\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Update Q-value\n",
    "        best_next_action = np.argmax(Q[tuple(next_state)])\n",
    "        Q[tuple(state)][action] = Q[tuple(state)][action] + alpha * (reward + gamma * Q[tuple(next_state)][best_next_action] - Q[tuple(state)][action])\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "    # Decay epsilon\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Track rewards for plotting\n",
    "    rewards = []\n",
    "\n",
    "    # Train the agent\n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = choose_action(tuple(state))\n",
    "            next_state, reward, done, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Update Q-value\n",
    "            best_next_action = np.argmax(Q[tuple(next_state)])\n",
    "            Q[tuple(state)][action] = Q[tuple(state)][action] + alpha * (reward + gamma * Q[tuple(next_state)][best_next_action] - Q[tuple(state)][action])\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        # Decay epsilon\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "        \n",
    "        rewards.append(total_reward)\n",
    "        \n",
    "        if (episode + 1) % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.plot(rewards)\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Total Reward')\n",
    "            plt.title('Training Progress')\n",
    "            plt.show()\n",
    "            print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # Extract the best route\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    best_route = [state]\n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(Q[tuple(state)])\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        best_route.append(next_state)\n",
    "        state = next_state\n",
    "\n",
    "    print(\"Best Route:\", best_route)\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "    \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Extract the best route\n",
    "state, info = env.reset()\n",
    "done = False\n",
    "best_route = [state]\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(Q[tuple(state)])\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    best_route.append(next_state)\n",
    "    state = next_state\n",
    "\n",
    "print(\"Best Route:\", best_route)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
