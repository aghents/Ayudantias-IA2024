{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayudantia 3 IA\n",
    "\n",
    "## Caso practico de un sistema de recuperación de información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "\n",
    "1. Entender en lo que consiste information retrieval (apunte)\n",
    "2. Revisar las distintas maneras de preprocesar texto (apunte y codigo)\n",
    "3. Concepto de embedding y modelos (apunte y codigo)\n",
    "4. aplicando todo a nuestro caso (codigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agustin/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Corpus-Agro.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(20000) # generamos una muestra para no tener grandes tiempos de ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que existen documentos de varios idiomas. Por lo tanto tendremos que hacer preprocesamientos distintos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "sample['language'] = sample['Resumen'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en         12574\n",
      "es          4880\n",
      "fr          2536\n",
      "unknown       10\n",
      "Name: language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"language\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample[sample['language'].isin(['es', 'en', 'fr'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada lenguaje se procesa de manera distinta, porque tienen estructuras distintas!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos lematizar o aplicar stemming, en general no hay respuesta correcta sobre cual usar. Lo unico que si sabemos es que lematizing considera el contexto y stemming utiliza reglas simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta ayudantia usaremos stemming por su simplicidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unidecode in /home/agustin/.local/lib/python3.10/site-packages (1.3.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "# Inicializamos stemmer\n",
    "stemmer_spanish = SnowballStemmer('spanish')\n",
    "stemmer_english = SnowballStemmer('english')\n",
    "stemmer_french = SnowballStemmer('french')\n",
    "\n",
    "# Recolectamos stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('spanish') + \n",
    "                 nltk.corpus.stopwords.words('english') + \n",
    "                 nltk.corpus.stopwords.words('french'))\n",
    "\n",
    "# Procesar cada palabra\n",
    "def process_text(text, language):\n",
    "    text = text.lower() # minusculas\n",
    "    text = unidecode(text)  # removemos acentos\n",
    "    text = ''.join([c for c in text if c not in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~']) # removemos signos de puntuación\n",
    "\n",
    "\n",
    "    if language == 'es':\n",
    "        tokens = [stemmer_spanish.stem(word) for word in text.split()]\n",
    "    elif language == 'en':\n",
    "        tokens = [stemmer_english.stem(word) for word in text.split()]\n",
    "    elif language == 'fr':\n",
    "        tokens = [stemmer_french.stem(word) for word in text.split()]\n",
    "    else:\n",
    "        tokens = text.split()\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in stop_words] # obtenemos tokens\n",
    "    return tokens if tokens else None\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "sample['Tokens'] = sample.apply(lambda row: process_text(row['Resumen'], row['language']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les dejo el codigo similar para correr usando lematizer por si quieren probarlo\n",
    "\n",
    "```\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('spanish') + \n",
    "                 nltk.corpus.stopwords.words('english') + \n",
    "                 nltk.corpus.stopwords.words('french'))\n",
    "\n",
    "def process_text_lemmatize(text, language):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'])  \n",
    "    tokens = text.split()\n",
    "    if language == 'es':\n",
    "        # Placeholder for Spanish lemmatization\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    elif language == 'en':\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    elif language == 'fr':\n",
    "        # Placeholder for French lemmatization\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens if tokens else None\n",
    "\n",
    "sample['Tokens'] = sample.apply(lambda row: process_text_lemmatize(row['Resumen'], row['language']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos word2vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/agustin/.local/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/agustin/.local/lib/python3.10/site-packages (from gensim) (1.26.1)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/agustin/.local/lib/python3.10/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/agustin/.local/lib/python3.10/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /usr/lib/python3/dist-packages (from smart-open>=1.8.1->gensim) (1.13.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL de Documento</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>language</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83015</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/rus152849.pdf</td>\n",
       "      <td>Article 9 shall be amended to add the followin...</td>\n",
       "      <td>en</td>\n",
       "      <td>[articl, 9, shall, amend, add, follow, word, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73367</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/rus135937.pdf</td>\n",
       "      <td>The scope of this Regional Law shall be to est...</td>\n",
       "      <td>en</td>\n",
       "      <td>[scope, region, law, shall, establish, mechan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83583</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/wa180819.pdf</td>\n",
       "      <td>This Act, consisting of 68 sections divided in...</td>\n",
       "      <td>en</td>\n",
       "      <td>[act, consist, 68, section, divid, ten, part, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88739</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/fra198819.pdf</td>\n",
       "      <td>Le présent arrêté modifie l'arrêté du 10 févri...</td>\n",
       "      <td>fr</td>\n",
       "      <td>[present, arret, modif, larret, 10, fevri, 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/cos185748.pdf</td>\n",
       "      <td>La presente Directriz, considerando que en los...</td>\n",
       "      <td>es</td>\n",
       "      <td>[present, directriz, consider, rastroj, vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81242</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/arg72397.pdf</td>\n",
       "      <td>La presente Resolución aprueba el Plan Ganader...</td>\n",
       "      <td>es</td>\n",
       "      <td>[present, resolucion, aprueb, plan, ganader, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50051</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/tw181950.pdf</td>\n",
       "      <td>These Rules are enacted in accordance with the...</td>\n",
       "      <td>en</td>\n",
       "      <td>[rule, enact, accord, fisheri, act, aim, conse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/alg217931.pdf</td>\n",
       "      <td>Cette Loi, qui se compose de 6 Chapitres, a po...</td>\n",
       "      <td>fr</td>\n",
       "      <td>[cet, loi, compos, 6, chapitr, objet, fix, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29584</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/mac150045.pdf</td>\n",
       "      <td>This Regulation here determines the official l...</td>\n",
       "      <td>en</td>\n",
       "      <td>[regul, determin, offici, list, undesir, subst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>https://faolex.fao.org/docs/pdf/ecu85066.pdf</td>\n",
       "      <td>La presente Resolución modifica la que estable...</td>\n",
       "      <td>es</td>\n",
       "      <td>[present, resolucion, modif, establec, valor, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    URL de Documento  \\\n",
       "83015  https://faolex.fao.org/docs/pdf/rus152849.pdf   \n",
       "73367  https://faolex.fao.org/docs/pdf/rus135937.pdf   \n",
       "83583   https://faolex.fao.org/docs/pdf/wa180819.pdf   \n",
       "88739  https://faolex.fao.org/docs/pdf/fra198819.pdf   \n",
       "4957   https://faolex.fao.org/docs/pdf/cos185748.pdf   \n",
       "...                                              ...   \n",
       "81242   https://faolex.fao.org/docs/pdf/arg72397.pdf   \n",
       "50051   https://faolex.fao.org/docs/pdf/tw181950.pdf   \n",
       "10603  https://faolex.fao.org/docs/pdf/alg217931.pdf   \n",
       "29584  https://faolex.fao.org/docs/pdf/mac150045.pdf   \n",
       "5056    https://faolex.fao.org/docs/pdf/ecu85066.pdf   \n",
       "\n",
       "                                                 Resumen language  \\\n",
       "83015  Article 9 shall be amended to add the followin...       en   \n",
       "73367  The scope of this Regional Law shall be to est...       en   \n",
       "83583  This Act, consisting of 68 sections divided in...       en   \n",
       "88739  Le présent arrêté modifie l'arrêté du 10 févri...       fr   \n",
       "4957   La presente Directriz, considerando que en los...       es   \n",
       "...                                                  ...      ...   \n",
       "81242  La presente Resolución aprueba el Plan Ganader...       es   \n",
       "50051  These Rules are enacted in accordance with the...       en   \n",
       "10603  Cette Loi, qui se compose de 6 Chapitres, a po...       fr   \n",
       "29584  This Regulation here determines the official l...       en   \n",
       "5056   La presente Resolución modifica la que estable...       es   \n",
       "\n",
       "                                                  Tokens  \n",
       "83015  [articl, 9, shall, amend, add, follow, word, c...  \n",
       "73367  [scope, region, law, shall, establish, mechan,...  \n",
       "83583  [act, consist, 68, section, divid, ten, part, ...  \n",
       "88739  [present, arret, modif, larret, 10, fevri, 198...  \n",
       "4957   [present, directriz, consider, rastroj, vegeta...  \n",
       "...                                                  ...  \n",
       "81242  [present, resolucion, aprueb, plan, ganader, n...  \n",
       "50051  [rule, enact, accord, fisheri, act, aim, conse...  \n",
       "10603  [cet, loi, compos, 6, chapitr, objet, fix, reg...  \n",
       "29584  [regul, determin, offici, list, undesir, subst...  \n",
       "5056   [present, resolucion, modif, establec, valor, ...  \n",
       "\n",
       "[19990 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def word2vec_model():\n",
    "    w2v_model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4,sg=0)\n",
    "    \n",
    "    w2v_model.build_vocab(sample[\"Tokens\"])\n",
    "    w2v_model.train(sample[\"Tokens\"], total_examples=w2v_model.corpus_count, epochs=100, report_delay=1)\n",
    "    \n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = word2vec_model()\n",
    "w2v_model.save('word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vec = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6085088 , -0.33314288,  0.97723985, -3.4979072 , -1.3787006 ,\n",
       "       -3.9366825 , -0.7173811 , -2.7292817 , -2.1615949 ,  2.1315677 ,\n",
       "       -2.239666  , -1.62881   , -1.6008953 , -3.375209  , -2.8454742 ,\n",
       "        0.78373   ,  0.5334982 ,  4.662986  , -4.5115585 , -0.5237386 ,\n",
       "        0.4804591 ,  1.4360974 ,  7.359169  , -2.5666301 , -3.49994   ,\n",
       "        0.8984299 ,  1.2626542 , -1.6085345 ,  0.44806504,  0.27082896,\n",
       "        0.9195448 ,  0.8457727 , -6.024203  , -0.3039297 , -2.5927622 ,\n",
       "       -2.9156122 ,  5.666504  , -2.1638308 ,  4.8464613 , -3.6144726 ,\n",
       "        2.0086863 ,  3.781697  ,  2.9543576 ,  2.3458393 , -2.4440458 ,\n",
       "        1.9248039 , -6.311608  ,  2.598514  ,  1.7351967 ,  4.239978  ,\n",
       "        3.403509  ,  0.06281841, -4.599982  , -1.2823732 , -3.9265575 ,\n",
       "        1.8195521 , -6.037924  ,  0.03103166,  0.9647852 , -2.6252034 ,\n",
       "       -2.5061555 , -4.042404  ,  0.5638172 ,  2.3539836 , -2.8392386 ,\n",
       "       -3.175306  ,  2.6528263 ,  0.6644061 , -0.08461104,  3.8840039 ,\n",
       "       -0.6282246 , -5.0557246 , -0.3178334 ,  0.54481596,  0.3042845 ,\n",
       "        2.2847707 , -1.8962778 , -3.0211368 ,  0.91263   ,  1.9435182 ,\n",
       "        1.4473028 , -0.19312866, -0.38074696,  1.214543  ,  0.5103753 ,\n",
       "        2.1002629 ,  0.6359644 ,  0.04332855, -5.9364443 , -6.7434845 ,\n",
       "       -0.52221644,  0.13364373, -3.2318892 ,  0.93022805,  2.4660661 ,\n",
       "        0.97784966, -0.2083935 ,  2.1536002 ,  3.8486435 ,  0.11497758],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vec['china'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_w2v(doc_tokens):\n",
    "    embeddings = []\n",
    "    if len(doc_tokens) < 1:\n",
    "        return np.zeros(100)\n",
    "    else:\n",
    "        for tok in doc_tokens:\n",
    "            if tok in w2v_model.wv.key_to_index:\n",
    "                embeddings.append(w2v_model.wv.get_vector(tok))\n",
    "            else:\n",
    "                embeddings.append(np.random.rand(100))\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "def ranking_ir(text, sample):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Overview of agricultural science\"\n",
    "\n",
    "# Use the ranking function\n",
    "top_documents = ranking_ir(query, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These Regulations are enacted to   strengthen ...</td>\n",
       "      <td>0.296117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These Regulations are formulated in accordance...</td>\n",
       "      <td>0.269950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This Law determines the notion, forms, and gen...</td>\n",
       "      <td>0.269081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Decision, as in accordance with the provi...</td>\n",
       "      <td>0.258448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The development of rural tourism is a need, wh...</td>\n",
       "      <td>0.251294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>These Measures, consisting of 34 Articles,  ar...</td>\n",
       "      <td>0.249004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The National youth policy is part of the Rwand...</td>\n",
       "      <td>0.248503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These Opinions are developed to improve the lo...</td>\n",
       "      <td>0.246489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In order to protect human health the meat of h...</td>\n",
       "      <td>0.244404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This Fourteenth Five-Year Plan for Cold Chain ...</td>\n",
       "      <td>0.241973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Resumen  Similarity\n",
       "0  These Regulations are enacted to   strengthen ...    0.296117\n",
       "1  These Regulations are formulated in accordance...    0.269950\n",
       "2  This Law determines the notion, forms, and gen...    0.269081\n",
       "3  This Decision, as in accordance with the provi...    0.258448\n",
       "4  The development of rural tourism is a need, wh...    0.251294\n",
       "5  These Measures, consisting of 34 Articles,  ar...    0.249004\n",
       "6  The National youth policy is part of the Rwand...    0.248503\n",
       "7  These Opinions are developed to improve the lo...    0.246489\n",
       "8  In order to protect human health the meat of h...    0.244404\n",
       "9  This Fourteenth Five-Year Plan for Cold Chain ...    0.241973"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ustedes todo:\n",
    "\n",
    "1. entender las diferencias al aplicar cbow y skipgram, ajustar los hiperparametros para tener mejor rendimiento\n",
    "2. terminan la funcion para evaluar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
